{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Importando bibliotecas necessárias\n",
    "\n",
    "- Tensorflow e keras: Criação e treinamento do modelo\n",
    "- Sklearn: Funções de processamento de dados\n",
    "- matplotlib e seaborn: plotagem de gráficos do dataset\n",
    "- pandas: Manipulação dos datasets em CSV"
   ],
   "id": "730e4ce6033f5636"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Dot, Flatten, Dense, Dropout, Concatenate, Lambda, BatchNormalization\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.src.utils import plot_model\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pré-processamento de dataset\n",
    "\n",
    "Vamos abrir e pré-processar os dados do nosso dataset"
   ],
   "id": "7b51c7cb9e6b7988"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ratings_df = pd.read_csv('books/Ratings.csv')\n",
    "books_df = pd.read_csv('books/Books.csv')\n",
    "users_df = pd.read_csv('books/Users.csv')"
   ],
   "id": "18ad603378acefb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analisando a distribuição das notas\n",
    "\n",
    "Com o histograma, percebemos que existe uma grande predominancia de avaliações 0, que podem enviezar o nosso modelo."
   ],
   "id": "bce07e5dab5206ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(ratings_df[\"Book-Rating\"], bins=11, kde=False)\n",
    "plt.title(\"Distribuição das notas\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "8b17efbf8828e043",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Removemos então as avaliações nota 0.",
   "id": "c3f3373dc222146c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ratings_df = ratings_df[ratings_df[\"Book-Rating\"] > 0]",
   "id": "8100a641b946820",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(ratings_df[\"Book-Rating\"], bins=10, kde=False)  # Ratings vão de 0 a 10\n",
    "plt.title(\"Distribuição das notas\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "f454f57670ca732e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Codificar os IDs para índices inteiros discretos\n",
    "\n",
    "Dados não-numéricos (ISBN do livro, nome do autor, etc) devem ser convertidos em valores discretos para input na rede"
   ],
   "id": "11fbaf2267b6283"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "books_df = books_df[[\"ISBN\", \"Book-Author\"]].dropna()\n",
    "books_df[\"Book-Author\"] = books_df[\"Book-Author\"].str.strip().str.lower()\n",
    "\n",
    "isbn_to_title = dict(zip(books_df[\"ISBN\"], books_df[\"Book-Title\"]))\n",
    "\n",
    "def convert_isbn_to_title(isbn):\n",
    "    return isbn, isbn_to_title.get(isbn, \"Título não encontrado\")"
   ],
   "id": "ed4e24c30de2fe8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "author2id = {author: idx for idx, author in enumerate(books_df[\"Book-Author\"].unique())}\n",
    "books_df[\"author_id\"] = books_df[\"Book-Author\"].map(author2id)\n",
    "isbn_to_author_id = dict(zip(books_df[\"ISBN\"], books_df[\"author_id\"]))"
   ],
   "id": "a3b8ccdc8668631f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ratings_df[\"Book-Author\"] = ratings_df[\"ISBN\"].map(isbn_to_author_id)\n",
    "\n",
    "ratings_df = ratings_df.dropna(subset=[\"Book-Author\"])\n",
    "ratings_df[\"Book-Author\"] = ratings_df[\"Book-Author\"].astype(int)"
   ],
   "id": "cbc291c3a39cc3bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A idade precisa ser normalizada e usuários sem idade informada, recebem a idade média do dataset para evitar valores nulos, uma vez que a idade é um atributo importante para classificar similaridade entre usuários",
   "id": "cc0e1a51f93d122a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "users_df[\"Age\"] = users_df[\"Age\"].fillna(users_df[\"Age\"].median())\n",
    "\n",
    "user_age_map = dict(zip(users_df[\"User-ID\"], users_df[\"Age\"]))\n",
    "ratings_df[\"user_age\"] = ratings_df[\"User-ID\"].map(user_age_map)\n",
    "\n",
    "ratings_df[\"user_age\"] = ratings_df[\"user_age\"].astype(float)\n",
    "\n",
    "scaler_age = StandardScaler()\n",
    "ratings_df[\"user_age_scaled\"] = scaler_age.fit_transform(ratings_df[[\"user_age\"]])"
   ],
   "id": "52ebdda33747d31e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As notas também são normalizadas para mitigar possíveis viéses causados pela distribuição desigual de notas no dataset.",
   "id": "a0ade6ce284d9345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "ratings_df[\"Book-Rating\"] = scaler.fit_transform(ratings_df[[\"Book-Rating\"]])\n",
    "\n",
    "\n",
    "print(f\"Média (do scaler): {scaler.mean_[0]:.2f}\")\n",
    "print(f\"Desvio padrão (do scaler): {scaler.scale_[0]:.2f}\")"
   ],
   "id": "5040f4ee8afa978e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_encoder = LabelEncoder()\n",
    "book_encoder = LabelEncoder()\n",
    "author_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df[\"User-ID\"] = user_encoder.fit_transform(ratings_df[\"User-ID\"])\n",
    "ratings_df[\"ISBN\"] = book_encoder.fit_transform(ratings_df[\"ISBN\"])\n",
    "ratings_df[\"Book-Author\"] = author_encoder.fit_transform(ratings_df[\"Book-Author\"])\n",
    "\n",
    "num_users = ratings_df[\"User-ID\"].nunique()\n",
    "num_books = ratings_df[\"ISBN\"].nunique()\n",
    "num_authors = ratings_df[\"Book-Author\"].nunique()"
   ],
   "id": "f45fa5f815dc3ee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_df, val_df = train_test_split(ratings_df, test_size=0.2, random_state=42)",
   "id": "e12c7c4533146d3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Avaliando a esparcidade do dataset\n",
    "\n",
    "Espacidade, ou a predominancia de valores ausentes em uma matriz de dados, é uma métrica útil para guiar decisões a respeito da arquitetura e tamanho do modelo"
   ],
   "id": "b9121ff2505d2ac0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_sparsity(df, user_col=\"User-ID\", item_col=\"ISBN\"):\n",
    "    num_users = df[user_col].nunique()\n",
    "    num_items = df[item_col].nunique()\n",
    "    num_interactions = len(df)\n",
    "\n",
    "    total_possible = num_users * num_items\n",
    "    sparsity = 1 - (num_interactions / total_possible)\n",
    "\n",
    "    print(f\"Número de usuários: {num_users}\")\n",
    "    print(f\"Número de livros: {num_items}\")\n",
    "    print(f\"Número de interações: {num_interactions}\")\n",
    "    print(f\"Total possível de interações: {total_possible}\")\n",
    "    print(f\"Esparsidade: {sparsity:.4f} ({sparsity*100:.2f}%)\")\n",
    "\n",
    "    return sparsity\n",
    "\n",
    "compute_sparsity(train_df)"
   ],
   "id": "ab5dcc93e85ff8f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criando o modelo",
   "id": "5d366e802feafa33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embedding_dim = 4\n",
    "\n",
    "user_input = Input(shape=(1,), name=\"user_input\")\n",
    "book_input = Input(shape=(1,), name=\"book_input\")\n",
    "author_input = Input(shape=(1,), name=\"author_input\")\n",
    "age_input = Input(shape=(1,), name=\"user_age\")\n",
    "\n",
    "user_embedding = Embedding(num_users, embedding_dim, name=\"user_embedding\", embeddings_regularizer=l2(1e-6))(user_input)\n",
    "book_embedding = Embedding(num_books, embedding_dim, name=\"book_embedding\", embeddings_regularizer=l2(1e-6))(book_input)\n",
    "author_embedding = Embedding(num_authors, embedding_dim, name=\"author_embedding\", embeddings_regularizer=l2(1e-6))(author_input)\n",
    "\n",
    "user_vec = Flatten()(user_embedding)\n",
    "book_vec = Flatten()(book_embedding)\n",
    "author_vec = Flatten()(author_embedding)\n",
    "\n",
    "x = Concatenate()([user_vec, book_vec, author_vec, age_input])\n",
    "\n",
    "outputs = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[user_input, book_input, author_input, age_input], outputs=outputs)\n",
    "model.compile(optimizer=\"adam\", loss=Huber(), metrics=[\"mae\"])\n",
    "model.summary()"
   ],
   "id": "55f276758dc8a5ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_model(model, to_file=\"model_plot.png\", show_shapes=True, show_layer_names=True, dpi=300)",
   "id": "1bbdb5dcbe664ead",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Treinando a rede",
   "id": "debe9572f934c0d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)",
   "id": "50c78f1adb6ded56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    [train_df[\"User-ID\"].values, train_df[\"ISBN\"].values, train_df[\"Book-Author\"].values, train_df[\"user_age_scaled\"].values],\n",
    "    train_df[\"Book-Rating\"].values,\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    batch_size=32,\n",
    "    validation_data=(\n",
    "        [val_df[\"User-ID\"].values, val_df[\"ISBN\"].values, val_df[\"Book-Author\"].values, val_df[\"user_age_scaled\"].values],\n",
    "        val_df[\"Book-Rating\"].values\n",
    "    ),\n",
    "    callbacks=[early_stop])"
   ],
   "id": "80f4653677216038",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history.history['loss']",
   "id": "171c995b86199354",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history.history['val_loss']",
   "id": "180f517519e8d008",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Loss (Erro de Huber)\")\n",
    "plt.title(\"Loss vs Época\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "4a6d2531088a2b70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Val Loss (Erro de Huber)\")\n",
    "plt.title(\"Val Loss vs Época\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "bcb65eb4b8ed0d84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Podemos salvar o modelo para não precisar treiná-lo novamente toda vez",
   "id": "836a52294a80fe68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.save(\"embeddings.keras\")",
   "id": "a5d6ea4346a1115e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Resultados\n",
    "\n",
    "Podemos abrir o nosso modelo salvo e utilizar os embeddings gerados para calcular similaridades"
   ],
   "id": "e444463def112bab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = load_model(\"embeddings.keras\")",
   "id": "a769e562c0cd50e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "book_embeddings = model.get_layer(\"book_embedding\").get_weights()[0]\n",
    "user_embeddings = model.get_layer(\"user_embedding\").get_weights()[0]\n",
    "author_embeddings =model.get_layer(\"author_embedding\").get_weights()[0]"
   ],
   "id": "cb4b7dc4ca575940",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Encontrando similares on-the-fly\n",
    "\n",
    "A abordagem mais comum é gerar uma matriz de distancia com todos os itens que geraram embeddings (livros, autores, usuários). Porém essas matrizes seriam muito grandes devido a quantidade de itens que estamos lidando.\n",
    "Portanto, utilizaremos uma função que calcula as distancias apenas de um único item determinado, ordenando os resultados de maneira decrescente para obter os itens mais próximos."
   ],
   "id": "a653c7024d49811f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def recommend_similar_books_fast(book_id, top_n=5):\n",
    "    try:\n",
    "        book_idx = book_encoder.transform([book_id])[0]\n",
    "    except:\n",
    "        print(\"Book ID não encontrado.\")\n",
    "        return []\n",
    "\n",
    "    target_embedding = book_embeddings[book_idx].reshape(1, -1)\n",
    "\n",
    "    similarities = cosine_similarity(target_embedding, book_embeddings)[0]\n",
    "\n",
    "    similar_indices = similarities.argsort()[::-1][1:top_n+1]\n",
    "\n",
    "    similar_books = [book_encoder.inverse_transform([i])[0] for i in similar_indices]\n",
    "    scores = [round(similarities[i], 4) for i in similar_indices]\n",
    "\n",
    "    return list(zip(similar_books, scores))"
   ],
   "id": "d54c5077306433f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def recommend_similar_users_fast(user_id, top_n=5):\n",
    "    try:\n",
    "        user_idx = user_encoder.transform([user_id])[0]\n",
    "    except:\n",
    "        print(\"User ID não encontrado.\")\n",
    "        return []\n",
    "\n",
    "    target_embedding = user_embeddings[user_idx].reshape(1, -1)\n",
    "\n",
    "    similarities = cosine_similarity(target_embedding, user_embeddings)[0]\n",
    "\n",
    "    similar_indices = similarities.argsort()[::-1][1:top_n+1]\n",
    "\n",
    "    similar_users = [user_encoder.inverse_transform([i])[0] for i in similar_indices]\n",
    "    scores = [round(similarities[i], 4) for i in similar_indices]\n",
    "\n",
    "    return list(zip(similar_users, scores))"
   ],
   "id": "ca680f9f24d4fca3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def recommend_similar_authors_fast(author_name, top_n=5):\n",
    "    try:\n",
    "        author_idx = author2id[author_name.lower().strip()]\n",
    "    except KeyError:\n",
    "        print(\"Autor não encontrado.\")\n",
    "        return []\n",
    "\n",
    "    target_embedding = author_embeddings[author_idx].reshape(1, -1)\n",
    "\n",
    "    similarities = cosine_similarity(target_embedding, author_embeddings)[0]\n",
    "\n",
    "    similar_indices = similarities.argsort()[::-1][1:top_n+1]\n",
    "\n",
    "    id2author = {idx: author for author, idx in author2id.items()}\n",
    "    similar_authors = [(id2author[i], round(similarities[i], 4)) for i in similar_indices]\n",
    "\n",
    "    return similar_authors"
   ],
   "id": "a2dac0005fcb9c09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualizando os resultados",
   "id": "62f6d3fd4e2adb3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "recommend_similar_users_fast(276729, top_n=5)",
   "id": "998c89dc3ae75d7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "recommend_similar_authors_fast(\"Machado de Assis\", top_n=5)",
   "id": "60653d26ba4d3d2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "recommended_books = recommend_similar_books_fast(\"0385504209\", top_n=5)\n",
    "convert_isbn_to_title(recommended_books[1][0])"
   ],
   "id": "dff76f902d24880c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
