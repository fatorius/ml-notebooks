{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Importando as bibliotecas necessárias\n",
    "\n",
    "Nesse notebook as bibliotecas utilizadas serão:\n",
    "\n",
    "* Tensorflow - Para criação e treinamento das redes neurais e outras funções de pré-processamento de dados\n",
    "\n",
    "E outras bibliotecas nativas do Python - time e os"
   ],
   "id": "dd92736f8b1f5860"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T14:35:30.783839Z",
     "start_time": "2025-04-05T14:35:27.801113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:35:33.896223Z",
     "start_time": "2025-04-05T14:35:33.894262Z"
    }
   },
   "cell_type": "code",
   "source": "arquivo_path = \"combined.txt\"",
   "id": "51e792f9154c1a05",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:35:35.102078Z",
     "start_time": "2025-04-05T14:35:34.833216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = open(arquivo_path, 'rb').read().decode(encoding='utf-8')\n",
    "print(f'O texto contém: {len(text)} caracteres')\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} caracteres únicos')"
   ],
   "id": "5e72d3f183f64894",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O texto contém: 44418189 caracteres\n",
      "141 caracteres únicos\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pré-processando os dados\n",
    "\n",
    "Para a nossa rede, cada caracter precisa ser convertido em um valor numérico para identificação, uma vez que as redes neurais só trabalham com números."
   ],
   "id": "c981e07eb315571e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:35:38.870566Z",
     "start_time": "2025-04-05T14:35:38.746428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "caracteres_para_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "\n",
    "ids_para_caracteres = tf.keras.layers.StringLookup(\n",
    "    vocabulary=caracteres_para_ids.get_vocabulary(), invert=True, mask_token=None)\n"
   ],
   "id": "f3210605cde6faf3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 11:35:38.763028: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-04-05 11:35:38.763211: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-04-05 11:35:38.763224: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743863738.763554   68631 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1743863738.763604   68631 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:35:48.983954Z",
     "start_time": "2025-04-05T14:35:48.981070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função para converter de volta os IDs em textos\n",
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(caracteres_para_ids(ids), axis=-1)"
   ],
   "id": "2f011f0bdeb1fe68",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dividindo o texto em sequencias de entrada\n",
    "\n",
    "Em seguida, precisamos dividir o texto em sequencias menores de entrada para que a nossa rede possa receber no treinamento\n"
   ],
   "id": "19214bf3d2db19e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:01.731960Z",
     "start_time": "2025-04-05T14:35:56.139277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "texto_em_ids = caracteres_para_ids(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "dataset_de_ids = tf.data.Dataset.from_tensor_slices(texto_em_ids)"
   ],
   "id": "903b6bd66544a0c3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:03.092284Z",
     "start_time": "2025-04-05T14:36:03.089100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tamanho_da_sequencia_em_caracteres = 100\n",
    "dados_por_dataset = len(text) // (tamanho_da_sequencia_em_caracteres + 1)"
   ],
   "id": "364eda10d720322a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:04.826272Z",
     "start_time": "2025-04-05T14:36:04.814175Z"
    }
   },
   "cell_type": "code",
   "source": "sequencias = dataset_de_ids.batch(tamanho_da_sequencia_em_caracteres+1, drop_remainder=True)",
   "id": "dd49183b8c10964f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:06.164045Z",
     "start_time": "2025-04-05T14:36:06.161435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def divide_input(sequencia):\n",
    "    input_text = sequencia[:-1]\n",
    "    target_text = sequencia[1:]\n",
    "    return input_text, target_text"
   ],
   "id": "89c3b37f33f60b17",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:07.821380Z",
     "start_time": "2025-04-05T14:36:07.791968Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = sequencias.map(divide_input)",
   "id": "2a996385d35af1be",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Criando os lotes de treinamento\n",
    "Utilizando funções do Tensorflow, vamos converter os dados em um formato de entrada válido para a nossa rede neural"
   ],
   "id": "6b62013b9a718144"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:10.033632Z",
     "start_time": "2025-04-05T14:36:10.020075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TAMANHO_BATCH = 64\n",
    "\n",
    "# Tamanho do buffer para embaralhar os exemplos do dataset\n",
    "TAMANHO_BUFFER = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(TAMANHO_BUFFER)\n",
    "    .batch(TAMANHO_BATCH, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))"
   ],
   "id": "4c2d8416874c850f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Construindo o modelo\n",
    "Utilizando o `keras.model`, vamos criar uma rede neural recorrente com duas camadas LSTM (Long short-term memory).\n",
    "No artigo original, o autor cria um modelo muito semelhante com uma única camada GRU (Gated Recurrent Unit), que são mais baratas computacionalmente porém possuem uma menor eficiencia devido a sua arquitetura com 2 portões (atualização e redefinição), ao contrário da LSTM que possui 3 portões (entrada, esquecimento e saída).\n",
    "\n",
    "A arquitetura da rede é bem simples:\n",
    "- Uma camada embedding com a dimensão de 256\n",
    "- Duas camadas LSTM com 2048 neuronios\n",
    "- Uma camada dense com o mesmo tamanho que a quantidade de caracteres, onde cada neurônio representa um caracter\n",
    "\n",
    "O uso de duas camadas LSTM garante que o modelo aprenda padrões de maneira eficiente e com maior precisão"
   ],
   "id": "ca4fb645a47eb479"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:32.708249Z",
     "start_time": "2025-04-05T14:36:32.704270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dimensao_de_embedding = 256\n",
    "neuronios_lstm = 2048"
   ],
   "id": "6a5a2e605a28386b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:36.291182Z",
     "start_time": "2025-04-05T14:36:36.282678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ModeloDeLinguagem(tf.keras.Model):\n",
    "  def __init__(self, tamanho_do_vocabulario, dimensao_de_embedding, neuronios_lstm):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(tamanho_do_vocabulario, dimensao_de_embedding)\n",
    "    self.lstm1 = tf.keras.layers.LSTM(neuronios_lstm,\n",
    "                                      return_sequences=True,\n",
    "                                      return_state=True)\n",
    "    self.lstm2 = tf.keras.layers.LSTM(neuronios_lstm,\n",
    "                                      return_sequences=True,\n",
    "                                      return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(tamanho_do_vocabulario)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = self.embedding(inputs, training=training)\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "    if states is None:\n",
    "        h0_1 = tf.zeros((batch_size, self.lstm1.units))\n",
    "        c0_1 = tf.zeros((batch_size, self.lstm1.units))\n",
    "        x, h1, c1 = self.lstm1(x, initial_state=[h0_1, c0_1], training=training)\n",
    "\n",
    "        h0_2 = tf.zeros((batch_size, self.lstm2.units))\n",
    "        c0_2 = tf.zeros((batch_size, self.lstm2.units))\n",
    "        x, h2, c2 = self.lstm2(x, initial_state=[h0_2, c0_2], training=training)\n",
    "    else:\n",
    "        (h1, c1), (h2, c2) = states\n",
    "        x, h1, c1 = self.lstm1(x, initial_state=[h1, c1], training=training)\n",
    "        x, h2, c2 = self.lstm2(x, initial_state=[h2, c2], training=training)\n",
    "\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "        return x, [(h1, c1), (h2, c2)]\n",
    "    else:\n",
    "        return x"
   ],
   "id": "1a6de87988446644",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T14:36:40.051271Z",
     "start_time": "2025-04-05T14:36:40.032352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ModeloDeLinguagem(\n",
    "    tamanho_do_vocabulario=len(caracteres_para_ids.get_vocabulary()),\n",
    "    dimensao_de_embedding=dimensao_de_embedding,\n",
    "    neuronios_lstm=neuronios_lstm)"
   ],
   "id": "f7cb30a02386f9cb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Treinando o modelo!!!!\n",
   "id": "c3ca15cbb43921d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ],
   "id": "e65c8981fbd4266c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Salva os pesos do modelo em checkpoints do treinamento\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ],
   "id": "ae7644f299ebaf77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "EPOCHS = 30",
   "id": "c452eeee2029420f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])",
   "id": "ba00248710905124",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    return predicted_chars, states"
   ],
   "id": "9d5ceddd391369a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "one_step_model = OneStep(model, ids_para_caracteres, caracteres_para_ids)",
   "id": "2e2401f56c737202",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Ao verme'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ],
   "id": "46cbf0f900d201cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
